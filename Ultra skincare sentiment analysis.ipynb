{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8(Week 9)\n",
    "\n",
    "## Name: Theresa Louise Bazudde"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import itertools\n",
    "import re\n",
    "from typing import Any, Optional, Sequence, Union\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 1_000\n",
    "\n",
    "#removing stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Lemmatizing\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#word cloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#sentient analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "#model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Columns\n",
    "- Review Title: The title of the review.\n",
    "- Review_Text: The full text of the review.\n",
    "- Verified_Buyer: Whether the reviewer is a verified buyer of the product.\n",
    "- Review_Date: The date the review was published relative to the review scrape date.\n",
    "- Review_Location: The location of the reviewer.\n",
    "- Review_Upvotes: How many times the review was upvoted by other reviewers.\n",
    "- Review_Downvotes: How many times the review was downvoted by other reviewers.\n",
    "- Product: The name of the product the review was issued for.\n",
    "- Brand: The brand of the product.\n",
    "- Scrape Date: The date the data was pulled from the web.\n",
    "\n",
    "### Objectives\n",
    "1. Exploratory Data Analysis.\n",
    "2. Sentiments Analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\user\\Documents\\Folder\\CSV\\UltaSkincareReviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset info\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains both numerical and categorical data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratoty Data Analysis\n",
    "\n",
    "The following analysis will be performed\n",
    "<br>-checking for null values and removing them\n",
    "<br>-converting the Review_Text column to string data type\n",
    "<br>-converting Review_Text column to lowercase\n",
    "<br>-changing all contractions to their full form\n",
    "<br>-splitting data into numerical and categorical\n",
    "<br>-making count plots to know whcih products were reviewed more and if buyers are verified or not"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I did not collect the data myself, I must check for null values as they would cause errors down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is large and threfore removing a few data points would cause a major difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null values\n",
    "df = df[~df[\"Review_Text\"].isnull()]\n",
    "df = df[~df[\"Review_Location\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the null are gone\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as to have uniform data types in the column, all data is changed to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing all reviews to string variables\n",
    "df['Review_Text'] = df[\"Review_Text\"].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As python is a case sensitive language, the review text must all be in lower case so that for example the word Love and love would falsely be identified as different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing all to lower case\n",
    "df['Review_Text'] = df['Review_Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All contractions in the review text column are converted to their full form fpr better analysis\n",
    "A dictionary containing contractions and their full forms is created then passed to a function that converts them to their full form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a dictionary of contractions\n",
    "contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"'s\": \" is\"\n",
    "}\n",
    "#changing contactions to full form\n",
    "df['Review_Text'] = df['Review_Text'].apply(lambda x: ' '.join([contractions.get(word, word) for word in x.split()]))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A count plot for the products to determine which product is more popular amongst those reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#products\n",
    "sns.countplot(y='Product', data=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Daily Superfoliant and Daily Microfoliant are the most popular among the reviewed products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word CLoud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_reviews = df.groupby('product')['review'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# create a word cloud for each product\n",
    "for index, row in grouped_reviews.iterrows():\n",
    "    product = row['product']\n",
    "    text = row['review']\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white', max_words=50, contour_width=3, contour_color='steelblue').generate(text)\n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(product)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentient Analysis\n",
    "Questions to be answered are\n",
    "<ol>\n",
    "<li>Are most reviews positive or negative?</li>\n",
    "<li>Which products have majority negative reviews?</li>\n",
    "<li>Which have majority positive reviews?</li></ol>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words like 'the', 'and' etc are removed as they are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "df['Review_Text'] = df['Review_Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatising cuts words like 'running' to 'run' so that the root word is used to establish similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatising\n",
    "df['Review_Text'] = df['Review_Text'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special characters are also removed as they add no meaning to the sentient analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special characters\n",
    "df['Review_Text'] = df['Review_Text'].apply(lambda x: re.sub('[^A-Za-z0-9\\s]+', '', x))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob polarity\n",
    "TextBlob uses a machine learning algorithm to classify the sentiment of text as either positive or negative. \n",
    "<br> It has a built-in feature that is used to classify text as positive or negative based on a set of predefined words and their associated polarities. \n",
    "<br>Polarity is between -1 and 1 with negative words giving rise to negative values and positive words giving positive values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polarity of the reviews\n",
    "df['Polarity'] = df['Review_Text'].map(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity distribution\n",
    "The distribution of polarities amongst the various reviews is exmined to know whether most customers are happy or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing polarity distribution\n",
    "df[[\"Polarity\"]].hist(bins=20, figsize=(15, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These polarities are then converted to a sentient (either positive or negative) based on whether they're less than or greater than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Polarity'].apply(lambda x: 'positive' if x >= 0 else 'negative')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarities for the different products\n",
    "A count plot is used to analyze the different products and their sentients. The aim is to find out whether some products have more negative reviews than positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='Sentiment', kind='count', data=df, hue='Product', palette='bright')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "<ul>\n",
    "<li>The polarity distribution is skewed to the right. Therefore, majority of reviews are positive</li>\n",
    "<li>All products have more positive reviews than negative ones.</li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Review_Text'], df['Sentiment'], test_size=0.2)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a linear support vector machine (SVM) classifier\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf.score(X_test_vec, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
